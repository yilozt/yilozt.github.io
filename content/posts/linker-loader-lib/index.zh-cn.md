---
title: "笔记：程序员的自我修养——链接、装载、与库"
date: 2023-07-22T18:20:09+08:00
# draft: true
summary: 读书笔记
---

# 第一章 温故而知新

## CPU、内存和 IO 控制芯片
对于普通的程序开发者：大多时候关心 CPU，不用关心其他硬件细节；Java、Python、脚本语言开发者：CPU 也无需关心，编程语言已经提供了一个通用、无关平台的虚拟机。

## 计算机的硬件模型

* 早期
  
  CPU的频率很低、与内存差不多

  CPU、内存和其他设备连接到总线（Bus）上，每个IO设备有单独的控制芯片

* 南桥和北桥
  
  CPU 的频率高于内存频率，产生了与内存频率一致的系统总线。CPU 以倍频的方式与系统总线通信

  **北桥**：与 GPU 等高速设备通信

  **南桥**：与鼠标、键盘等低速设备通信

## 多核、SMP

* **对称多处理器（SMP）**：增加 CPU 的数量
* **多核处理器(Multi-core Processor)**：CPU内部共享缓存、保留多个核心

## 分层结构

每层之间相互通信，制定的通信协议：**接口** ，精心设计，尽量稳定

* 接口的下一层：提供接口
* 接口的上一层：使用接口

下层给上层提供服务

* API：运行库提供的接口（WindowsAPI、POSIX）
* 系统调用：操作系统提供的接口、往往以软件中断的形式提供（Linux int 0x80/ Windows 0x2E）

## 操作系统

和硬件打交道（驱动程序），屏蔽硬件细节，为上层的应用程序提供了使用硬件的接口

* Unix：被抽象成一系列文件，以文件的形式存在
* Windows：图形硬件——GDI；声音、多媒体——DirectX对象、磁盘——普通文件系统……

## 内存管理

早期，程序直接访问物理内存。进程之间的内存没有进行相互隔离。（进程A可以随意更改进程B的内容（Dos中一个程序可以随意更改任意内存，可以直接破坏操作系统本身的运行））

**程序需要的内存大约实际的物理内存时，该怎么办？** 将其他程序的数据暂时写入到磁盘里（换入和换出）

直接访问物理内存的缺点：

1. 地址空间不隔离：随意破坏和改写其他进程
2. 内存使用效率低：因为程序所使用的内存是**连续的**，在将空间进程的数据写入硬盘时，可能会导致大量数据的在硬盘中换入换出
3. 程序的运行地址不确定：程序在载入内存运行时，需要给它找一片空闲的内存。但这个空闲区域是不确定的。但程序在编写时，访问数据和跳转目标地址是固定的（地址在编译成二进制代码的时候已经固定了）——重定位

解决方案：添加中间层。将程序的地址（虚拟地址）映射到真实的物理地址。

好处：

**隔离** 进程有独立的地址空间（虚拟空间、可以看成一个很大的数组），只能访问到自己的地址空间

**分段映射** 一个程序进行需要多少内存，就从真实的物理地址里分配出等大小的一片区域，映射到进程的虚拟空间里（？）。物理内存的每一个字节和虚拟地址的每一个字节存在一一映射的关系。通常由硬件来完成

映射按程序为单位，内存不足时换入换出整个应用程序（粒度大）

> **局部性原理** 程序在运行时，大部分时间只会频繁地访问一小部分数据

**分页** 将地址空间划分成固定等大小的页，每页的大小由硬件决定

Intel 奔腾支持4KB或者4MB的页大小，但操作系统只能选择一种（4KB）

将页作为基本单位，将程序装载到内存、硬盘中：

* 虚拟页（Virtual Page, VP）：虚拟空间中的页
* 物理页（Physical Page, PP）：物理内存中的页
* 磁盘页（Disk Page, DP）：在磁盘中的页

**页错误** 进程需要的页不在内存中，硬件会捕获到这个消息，发错页错误，通知操作系统接管进程，从硬盘中载入对应的页。硬件本身就支持按页来存取、交换内存

**页面保护** 可以给每个页设置权限属性，且只有操作系统能够修改页的属性：保护自己、保护进程

**MMU（Memory Management Unit）** 实现虚拟存储的硬件，一般集成在 CPU 内部

**线程**

程序的一条执行路径。

线程=线程 ID+指令指针（PC）+寄存器集合+堆栈

进程共享的资源：程序的内存空间（代码段、数据段、堆）、进程级资源（打开的文件、信号）

进程私有资源：栈（一般认为是私有的，尽管其实可以被其他进程访问）、线程局部存储（Thread Local Storage, TLS）（操作系统提供，容量小）、寄存器（包括 PC 寄存器）

程序员的角度：

|  私有  | 共享   |
|:-------|:------|
| 局部变量| 全局变量 |
| 函数参数| 堆上的数据 |
| TLS 数据 | 函数里的静态变量 |
|          | 程序代码（代码段） |
|          | 打开的文件   |

进程调度：时间片轮转、优先级调度

设置优先级：

* Windows: `SetThreadPriority()` 函数
* Linux：设置 `pthread()` 的参数

操作系统会根据进程的表现自动调整优先级。

* IO 密集型线程：频繁等待的线程
* CPU 密集型线程：很少等待的线程

IO 密集型的线程更容易得到优先级的提升。

**饿死** 低优先级的进程总是被高优先级的进程抢占，自己没有办法运行。

* CPU 密集型的线程具有高优先级时，容易造成低优先级进程饿死（一直抢占CPU）
* IO 密集型型的线程会频繁进入等待状态，即使具有高优先级，低优先级的进程也有机会被运行

如何避免？进程的等待时间过长，优先级提升

## 抢占

进程被剥夺继续运行的权力（通常是时间片耗尽），进入就绪状态。

在早期的一些操作系统（Windows 3.1），进程是无法被抢占的，除非进程自己主动进入就绪状态

## Windows 与 Linux 的多线程支持

* Windows: 严格区分了线程和进程（`CreateProcess` / `CreateThread`）
* Linux: 支持贫乏、不存在真正意义上的线程概念——任务（Task，类似单进程的线程）
  * `fork` 复制当前进程，创建新进程
  * `exec` 使用新的可执行映像覆盖当前的可执行映像
  * `clone` 复制子进程并从指定位置开始执行

`clone` 可以在复制进程时，可以选择共享内存空间和打开文件，相当于创建了一个新线程
；`fork` 写时复制（COW, Copy on Write）

## 线程安全

* 竞争和原子操作：
  
  多个线程**同时读同一个全局变量**：安全

  多线程**同时写一个全局变量**：引发竞争问题（对于一个变量，每个线程中的值（寄存器中）**不同步**）

  exam：即使是简单的 `i++` 和 `i--` 也会引起竞争问题。有的体系结构会将这个操作分成三个指令：

  1. 从内存中读取 i，存入寄存器 `X`
  2. X++
  3. 将寄存器的值写入内存 i

  多线程无法保证寄存器中的值是同步的，线程向内存写入的值有可能会被其他线程覆盖。

  **原子操作**：单一的、无法拆分的计算机指令（Intel 的 Inc 指令）

  Windows API 里的 InterlockedAPI:

  * `InterlockedExchange`
  * `InterlockedDecrement`
  * `InterlockedIncrement`
  * `InterlockedXor`

  但使用原子操作函数只能解决简单、特定场合的竞争问题

* 同步、锁

  **同步** 在一个线程访问数据未结束的时候，其他线程不能对这个数据进行访问

  **锁** 访问之前获取（Acquire）锁、访问结束后释放（Release）锁。如果锁在获取是已经被占用，进程等待

  **二元信号量（Binary Semaphore）** 最简单的锁、只有`占用`和`非占用`两种状态

  **多元操作** 初始值为 N，允许多个线程并发访问；PV操作

  * **P 操作**：

    信号量-1，*获取资源*

    如果信号量<0，进入等待状态，否则继续执行（*资源不足，进入等待状态*）

  * **V 操作**：
  
    信号量+1 *释放资源*
    
    如果信号量的值<1，*唤醒一个等待资源的线程*

  **互斥量**：类似与二元信号量。

    区别：

    * 信号量：任何线程都可以获取、释放锁
    * 互斥量：哪个线程获取锁，哪个线程就负责释放锁

  **临界区**：更加严格的锁，只对本线程可见，其他线程不可见

  **读写锁**：多线程同时读一个共享变量——安全，同时写一个变量——会有竞争问题

    *频繁读、偶尔写*：用锁——保证正确但低效

    可以共享获取、也可以独占获取

    | 读写锁状态 | 以共享方式获取 | 以独占方式获取 |
    |:---------|:-------------|:--------|
    |自由 | 成功 | 成功 |
    |共享 | 成功 | 等待 |
    |独占 | 等待 | 等待 |

  **条件变量（Condition Variable）** 可以被等待和唤醒，被唤醒时，所有等待条件变量的线程一起恢复执行

## 可重入

* *可重入函数是线程安全的*
* 可重入：由于外部因素或函数自身的调用，在一个函数没有执行完毕时，又一次进入该函数执行，原因：
  1. 多个线程同时执行这个函数
  2. 函数（可能经过多层调用后）调用自身

  特点：

  1. 不使用任何(局部)静态或全局的非const变量。
  2. 不返回任何(局部)静态或全局的非const变量的指针。
  3. 仅依赖于调用方提供的参数。
  4. 不依赖任何单个资源的锁(mutex等)。
  5. 不调用任何不可重入的函数。

## 过度优化

**寄存器值** 编译器为了提高访问速度，将变量优化成一个寄存器值，而寄存器在进程中是私有的

* volatile 关键字：

  1. 防止编译器将变量缓存到寄存器中而不写回
  2. 放置编译器修改 volatile 变量的指令顺序

* 乱序执行

  `pInst = new T` 包含了三个步骤：

  1. 分配内存
  2. 调用构造函数T()
  3. 将指针赋值给 pInst

  步骤2和步骤3是可以颠倒的。Singleton 模式：

  ```cpp
  volatile T* pInst = nullptr;
  T* GetInstance() {
    if (pInst == NULL) {
        lock();
        if (pInst == NULL) {
            pInst = new T;
        }
        unlock();
    }
    return pInst;
  }
  ```

  假设步骤2,3顺序被交换了，另一个进程可能在判断第一个`pInst == NULL`时直接返回指针，但构造函数还没有被执行

  * barrier指令：阻止 CPU 将 barrier 之前的指令交换到 barrier 之后执行

  ```cpp
  // powerpc 的 barrier 指令
  #define barrier() __asm volatile("lwsync")

  volatile T* pInst = nullptr;
  T* GetInstance() {
    if (pInst == NULL) {
      lock();
        if (pInst == NULL) {
          T* tmp = new T;
          barrier(); // 保证构造函数执行后才输出指针
          pInst = tmp;
        }
        unlock();
      }
      return pInst;
    }
    ```

## 多线程的内部情况

线程的并发执行由多处理器和系统调用实现（内核线程），用户使用的线程并不是内核线程，而是用户态的用户线程。

*用户线程和内核线程并不总是一一对应*

三种线程模型：

* **一对一** 一个用户线程对应一个内核线程
  1. 受内核线程数量限制
  2. 上下文开销比较大
* **多对一** 多个用户线程对应一个内核线程
  1. 一个用户线程阻塞，导致其他线程也阻塞
  2. 几乎没有上下文切换的开销（在用户态实现）
  3. 线程数目不受限制

* **多对多** 结合上面两种模型的优点

